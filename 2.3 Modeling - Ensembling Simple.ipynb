{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/*@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "}\n",
       "@font-face {\n",
       "\tfont-family: \"Computer Modern\";\n",
       "\tfont-weight: bold;\n",
       "\tfont-style: oblique;\n",
       "\tsrc: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "}*/\n",
       "\n",
       ".navbar-brand, .current_kernel_logo {display:none}\n",
       ".container {\n",
       "    width:80%;    \n",
       "}\n",
       "\n",
       "h1 {\n",
       "\tfont-family: Helvetica, serif;\n",
       "}\n",
       "h4{\n",
       "\tmargin-top:12px;\n",
       "\tmargin-bottom: 3px;\n",
       "   }\n",
       "div.text_cell_render{\n",
       "\tfont-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "\tline-height: 145%;\n",
       "\tfont-size: 100%;\n",
       "\twidth:100%;\n",
       "\tmargin-left:auto;\n",
       "\tmargin-right:auto;\n",
       "}\n",
       ".CodeMirror{\n",
       "\t\tfont-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "}\n",
       ".text_cell_render h5 {\n",
       "\tfont-weight: 300;\n",
       "\tfont-size: 22pt;\n",
       "\t/*color: #4057A1;*/\n",
       "\tfont-style: italic;\n",
       "\tmargin-bottom: .5em;\n",
       "\tmargin-top: 0.5em;\n",
       "\tdisplay: block;\n",
       "}\n",
       "\n",
       ".warning{\n",
       "\tcolor: rgb( 240, 20, 20 )\n",
       "\t}   \n",
       "\n",
       "div.spoiler {\n",
       "\tdisplay: none;\n",
       "}\n",
       "\n",
       ".rendered_html code {\n",
       "\tborder: 0;\n",
       "\t/*background-color: #eee;*/\n",
       "\tfont-size: 100%;\n",
       "\tpadding: 1px 2px;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import css_from_file\n",
    "css_from_file('style/style.css')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape (3751, 1776)\n",
      "testing data shape (2501, 1776)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "def load(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"Activity\" not in df.columns:\n",
    "        df[\"Activity\"] = np.nan\n",
    "    return df.drop(\"Activity\",axis=1), df.Activity\n",
    "    \n",
    "X_tr, y_tr = load(\"data/boehringer/train.csv\")\n",
    "X_te, y_te = load(\"data/boehringer/test.csv\")\n",
    "\n",
    "print(\"training data shape\", X_tr.shape)\n",
    "print(\"testing data shape\", X_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "----------------\n",
    "\n",
    "Using your knowledge from 2.1 try to combine many models into a single solution.\n",
    "The simplest way to do this is to use `sklearn.ensemble.VotingClassifier`.\n",
    "\n",
    "1. Read the documentation http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier\n",
    "\n",
    "2. Which method is better for voting (`hard` or `soft`)? Why?\n",
    "\n",
    "3. Use more than 3 different algorithms. Check their performance separately and using VotingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "Your error is 0.469467792644\n",
      "rf\n",
      "Your error is 0.469467792644\n",
      "voting\n",
      "Your error is 0.459418713915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from cross_validation import cross_val_apply\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "clfs = [\n",
    "    ('rf',RandomForestClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('rf',RandomForestClassifier(n_estimators=100,n_jobs=1))\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    print(clf_name)\n",
    "    oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n",
    "                                      n_jobs=-1, decision_func=\"predict_proba\")\n",
    "\n",
    "    err = log_loss(y_tr, oof_predictions)\n",
    "    print(\"Your error is\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Double click to see the answers\n",
    "\n",
    "<div class=\"spoiler\">\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from cross_validation import cross_val_apply\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clfs = [\n",
    "    ('rf',RandomForestClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('gbm',GradientBoostingClassifier()),\n",
    "    ('et',ExtraTreesClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('xgb', XGBClassifier()),\n",
    "    ('bag', BaggingClassifier(n_estimators=100)),\n",
    "    ('svm', make_pipeline(StandardScaler(), SVC(probability=True)))\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    print(clf_name)\n",
    "    oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n",
    "                                      n_jobs=-1, decision_func=\"predict_proba\")\n",
    "\n",
    "    err = log_loss(y_tr, oof_predictions)\n",
    "    print(\"Your error is\", err)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_100\n",
      "Your error is 0.469467792644\n",
      "rf_100_depth_20\n",
      "Your error is 0.461622351538\n",
      "rf_300\n",
      "Your error is 0.458681784559\n",
      "pipe1\n",
      "Your error is 0.50965683573\n",
      "pipe2\n",
      "Your error is 0.512340810285\n",
      "voting\n",
      "Your error is 0.468530743728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pipe1 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    Imputer(),\n",
    "    PCA(n_components= 300),\n",
    "    XGBClassifier(),\n",
    "        )\n",
    "\n",
    "\n",
    "pipe2 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    Imputer(),\n",
    "    PCA(n_components= 100),\n",
    "    XGBClassifier(),\n",
    "        )\n",
    "\n",
    "clfs = [\n",
    "    ('rf_100',RandomForestClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('rf_100_depth_20',RandomForestClassifier(n_estimators=100,n_jobs=1, max_depth = 20)),\n",
    "    ('rf_300',RandomForestClassifier(n_estimators=300,n_jobs=1)),\n",
    "    ('pipe1', pipe1),\n",
    "    ('pipe2', pipe2)\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    print(clf_name)\n",
    "    oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n",
    "                                      n_jobs=-1, decision_func=\"predict_proba\")\n",
    "\n",
    "    err = log_loss(y_tr, oof_predictions)\n",
    "    print(\"Your error is\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bc\n",
      "Your error is 0.454333831858\n",
      "sgd\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba not implemented in estimator",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2c1af3459860>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n\u001b[1;32m---> 19\u001b[1;33m                                       n_jobs=-1, decision_func=\"predict_proba\")\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moof_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/media/ramya/D/datascienceretreat/model_pipelines_Pawel_Jankiewicz/notebooks/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_apply\u001b[1;34m(estimator, X, y, cv, n_jobs, decision_func, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1041\u001b[0m     \u001b[1;31m# Ensure the estimator has implemented the passed decision function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecision_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'not implemented in estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba not implemented in estimator"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clfs = [\n",
    "    #('pipe3', pipe3),\n",
    "    #('pipe4', pipe4),\n",
    "    ('bc', BaggingClassifier(n_estimators = 300)),\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    print(clf_name)\n",
    "    oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n",
    "                                      n_jobs=-1, decision_func=\"predict_proba\")\n",
    "\n",
    "    err = log_loss(y_tr, oof_predictions)\n",
    "    print(\"Your error is\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "Your error is 0.469467792644\n",
      "rf\n",
      "Your error is 0.442813586654\n",
      "bc\n",
      "Your error is 0.454333831858\n",
      "bc\n",
      "Your error is 0.483269833631\n",
      "voting\n",
      "Your error is 0.445699477614\n"
     ]
    }
   ],
   "source": [
    "clfs = [\n",
    "    ('rf',RandomForestClassifier(n_estimators=100,n_jobs=1)),\n",
    "    ('rf',RandomForestClassifier(n_estimators=300,n_jobs=1, criterion = 'entropy', max_depth = 50,\n",
    "                                 max_features = 350, random_state = 123)),\n",
    "    ('bc', BaggingClassifier(n_estimators = 300)),\n",
    "    ('bc', BaggingClassifier(n_estimators = 100))\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    print(clf_name)\n",
    "    oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n",
    "                                      n_jobs=-1, decision_func=\"predict_proba\")\n",
    "\n",
    "    err = log_loss(y_tr, oof_predictions)\n",
    "    print(\"Your error is\", err)\n",
    "    \n",
    "    \n",
    "clf = RandomForestClassifier(n_estimators=200, n_jobs=-1, criterion='entropy', max_depth=20, \n",
    "                                 min_samples_split=2, min_samples_leaf=1, max_features=250, \n",
    "                                 max_leaf_nodes=300, bootstrap=True, \n",
    "                                 oob_score=False, random_state=123, \n",
    "                                 verbose=0, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgbc\n",
      "Your error is 0.586488637215\n",
      "xgbc\n",
      "Your error is 0.589734950514\n",
      "xgbc\n",
      "Your error is 0.57011577935\n",
      "voting\n",
      "Your error is 0.571336008015\n"
     ]
    }
   ],
   "source": [
    "clfs = [\n",
    "    ('xgbc', XGBClassifier(n_estimators = 300, max_depth = 50, seed = 123)),\n",
    "    ('xgbc', XGBClassifier(n_estimators = 300, max_depth = 30, seed = 123)),\n",
    "    ('xgbc', XGBClassifier(n_estimators = 300, max_depth = 10, seed = 123))\n",
    "]\n",
    "\n",
    "voting_clf = ('voting',VotingClassifier(estimators=clfs,voting='soft'))\n",
    "\n",
    "for clf_name, clf in clfs + [voting_clf]:\n",
    "    print(clf_name)\n",
    "    oof_predictions = cross_val_apply(clf, X_tr, y_tr, cv=4,\n",
    "                                      n_jobs=-1, decision_func=\"predict_proba\")\n",
    "\n",
    "    err = log_loss(y_tr, oof_predictions)\n",
    "    print(\"Your error is\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 0.4882 accuracy, but can be useful in the ensemble\n",
    "nn_forest = BaggingClassifier(make_pipeline(\n",
    "                        make_union(RandomTreesEmbedding(n_estimators=10), \n",
    "                                   LazyTransformer()),\n",
    "                        StandardScaler(with_mean=False), \n",
    "                        VarianceThreshold(0.001),\n",
    "                        MLPClassifier((25,), alpha=10.0, verbose=False)), \n",
    "                        max_samples=0.75,\n",
    "                        max_features=0.75,\n",
    "                        n_estimators=10)\n",
    "\n",
    "#0.4678\n",
    "greg = RandomForestClassifier(min_samples_leaf = 2, min_samples_split = 4, n_estimators = 200)\n",
    "#0.4428\n",
    "karthick = RandomForestClassifier(n_estimators=300,n_jobs=1, criterion = 'entropy', max_depth = 50,\n",
    "                                 max_features = 350, random_state = 123)\n",
    "#0.447\n",
    "belal = RandomForestClassifier(n_estimators=200, n_jobs=-1, criterion='entropy', max_depth=20, \n",
    "                                 min_samples_split=2, min_samples_leaf=1, max_features=250, \n",
    "                                 max_leaf_nodes=300, bootstrap=True, \n",
    "                                 oob_score=False, random_state=123, \n",
    "                                 verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
